{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project goal was to gather data from 3 sources, all related to the Twitter account \"We Rate Dogs\".\n",
    "\n",
    "### First dataset \"twitter-archive-enhanced.csv\"\n",
    "\n",
    "The first dataset was a csv file.\n",
    "\n",
    "The dataset gives us the ids of 2356 tweets. It also has a field for the ids of the tweets it is a reply to or a retweet of. This allows us to distinguish easily between original tweets and replies / retweets.\n",
    "\n",
    "There were some non-optimal datatypes: timestamp was a string. \n",
    "\n",
    "doggo/floofer/pupper/puppo should be booleans instead of strings. And instead of 4 booleans for each nickname, I decided to have a single boolean value that detects the presence of one of the 4 words.\n",
    "\n",
    "The source field was simplified: it now gives the source name instead of a html tag.\n",
    "\n",
    "The expanded_urls is just the a list of the same tweet url times the number of images, plus additionnal urls from inside the tweet, which is less relevant that the image url itself (found in the second dataset and via the Twitter API). In addition, it has some missing values. I decided to discard the column.\n",
    "\n",
    "Finally, the name field was extracted via an algorithm that detects some string pattern (like \"This is ...\"), so although it seemed to work most of the time, there are common words that got mistaken as dog names.\n",
    "\n",
    "### Second dataset: \"image-predictions.tsv\"\n",
    "\n",
    "The second dataset was a tsv file fetched via a url. It contains information about 2075 tweets.\n",
    "\n",
    "This dataset gave us a correspondance between tweet ids and jpg urls. The unique jpg url could have allowed us to remove duplicates, but in the end, removing retweets and replies with information from the first dataset solved the problem.\n",
    "\n",
    "The dataset is the result of a machine learning algorithm that identify dog races and other items (like a laptop or a printer). It gives us three guesses (p1, p2, p3), with three highest confidence rates (p1_conf, p2_conf, p3_conf), and helpfully, a boolean value of the guess being a dog (p1_dog, p2_dog, p3_dog).\n",
    "\n",
    "For my analysis I decided to give each picture a single label. \n",
    "\n",
    "So, after trying different algorithms, I found that assuming a picture is a dog if at least one of the three best guesses of the machine learning algorithm is a dog, and giving the picture the label with highest confidence, is the most accurate according to my personnal assessment.\n",
    "\n",
    "### Third dataset: \"tweet-json.txt\"\n",
    "\n",
    "Unfortunately, after several e-mails with Twitter, they did not let me access their APIs before I gave us a thorough description of my project, which was not possible before I could see the data first.\n",
    "\n",
    "So I used the json file given by Udacity. It contains 2354 tweets.\n",
    "\n",
    "After careful examiniton of the file, I decided to keep only the Tweet id, the number of favorites and the number of retweets. \n",
    "\n",
    "All other potentially interesting fields like hashtags for example were quite sparse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
